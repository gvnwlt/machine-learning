# Evaulating Classification Models

# Confusion Matrix
  Using a confusion matrix helps to visualize the liklihood of false postives or negatives in a classification. 
  [true negative]  [false positive]    [TN][FP]
  [false negative] [true postive]      [FN][TP]

  total incorrect predictions = FN + FP
  total correct predictions = TN + TP
  percentage positive = TP / (FN + TP) or TP / (total ALL)

  The confusion matrix uses the prediction model trained via the training set and runs the test data against it 
  to see how accurate it is in its predictions. 
  
  